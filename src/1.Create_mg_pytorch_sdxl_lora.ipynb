{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d9bbf86da5e"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99c1c3fc2ca5"
      },
      "source": [
        "# Vertex AI Model Garden - Stable Diffusion XL 1.0 - LoRA serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3de7470326a2"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to download the popular LoRA (Low-Rank Adaptation) adapters from huggingface.co or civitai.com, and serve it together with the [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) model on Vertex AI for online prediction.\n",
        "\n",
        "### Objective\n",
        "\n",
        "- Deploy the base model and the LoRA adapter to a [Vertex AI Endpoint resource](https://cloud.google.com/vertex-ai/docs/predictions/using-private-endpoints).\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "264c07757582"
      },
      "source": [
        "## Before you begin\n",
        "\n",
        "**NOTE**:\n",
        "\n",
        "*  Jupyter runs lines prefixed with `!` as shell commands, and it interpolates Python variables prefixed with `$` into these commands.\n",
        "*  This Notebook demonstrate how to deploy a LoRA together the model [stabilityai/stable-diffusion-xl-base-1.0](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) on Vertex AI prediction endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c460088b873"
      },
      "source": [
        "### Set following variables for experiments environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "855d6b96f291",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# Cloud project id.\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The region you want to launch jobs in.\n",
        "REGION = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The Cloud Storage bucket for storing experiments output.\n",
        "# Fill it without the 'gs://' prefix.\n",
        "GCS_BUCKET = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# The service account for deploying fine tuned model. The service account looks like:\n",
        "# '<account_name>@<project>.iam.gserviceaccount.com'\n",
        "SERVICE_ACCOUNT = \"\"  # @param {type:\"string\"}\n",
        "\n",
        "# LORA source. Either hugging face or civitai. If huggingface_mode is false then LORA is downloaded from civitai\n",
        "HUGGINGFACE_MODE = False  # @param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e828eb320337"
      },
      "source": [
        "Initialize Vertex AI API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12cd25839741"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cc825514deb"
      },
      "source": [
        "### Define constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b42bd4fa2b2d"
      },
      "outputs": [],
      "source": [
        "# The pre-built serving docker image. It contains serving scripts and models.\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-diffusers-serve-opt:20240409_0836_RC00\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c250872074f"
      },
      "source": [
        "### Define common functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "354da31189dc"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import glob\n",
        "import os\n",
        "from io import BytesIO\n",
        "from google.cloud import aiplatform, storage\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def base64_to_image(image_str):\n",
        "    \"\"\"Convert base64 encoded string to an image.\"\"\"\n",
        "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
        "    return image\n",
        "\n",
        "\n",
        "def image_grid(imgs, rows=2, cols=2):\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new(\n",
        "        mode=\"RGB\", size=(cols * w + 10 * cols, rows * h), color=(255, 255, 255)\n",
        "    )\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w + 10 * i, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "def deploy_model(model_id, lora_id):\n",
        "    model_name = model_id\n",
        "    endpoint = aiplatform.Endpoint.create(display_name=f\"{model_name}-endpoint\")\n",
        "    serving_env = {\n",
        "        \"MODEL_ID\": model_id,\n",
        "        \"LORA_ID\": lora_id,\n",
        "        \"TASK\": \"text-to-image-sdxl\",\n",
        "    }\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_name,\n",
        "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "        serving_container_ports=[7080],\n",
        "        serving_container_predict_route=\"/predictions/diffusers_serving\",\n",
        "        serving_container_health_route=\"/ping\",\n",
        "        serving_container_environment_variables=serving_env,\n",
        "    )\n",
        "    model.deploy(\n",
        "        endpoint=endpoint,\n",
        "        machine_type=\"g2-standard-8\",\n",
        "        accelerator_type= \"NVIDIA_L4\",\n",
        "        accelerator_count=1,\n",
        "        deploy_request_timeout=1800,\n",
        "        service_account=SERVICE_ACCOUNT,\n",
        "    )\n",
        "    return model, endpoint\n",
        "\n",
        "\n",
        "def get_bucket_and_blob_name(filepath):\n",
        "    # The gcs path is of the form gs://<bucket-name>/<blob-name>\n",
        "    gs_suffix = filepath.split(\"gs://\", 1)[1]\n",
        "    return tuple(gs_suffix.split(\"/\", 1))\n",
        "\n",
        "\n",
        "def upload_local_dir_to_gcs(local_dir_path, gcs_dir_path):\n",
        "    \"\"\"Uploads files in a local directory to a GCS directory.\"\"\"\n",
        "    client = storage.Client()\n",
        "    bucket_name = gcs_dir_path.split(\"/\")[2]\n",
        "    bucket = client.get_bucket(bucket_name)\n",
        "    for local_file in glob.glob(local_dir_path + \"/**\"):\n",
        "        if not os.path.isfile(local_file):\n",
        "            continue\n",
        "        filename = local_file[1 + len(local_dir_path) :]\n",
        "        gcs_file_path = os.path.join(gcs_dir_path, filename)\n",
        "        _, blob_name = get_bucket_and_blob_name(gcs_file_path)\n",
        "        blob = bucket.blob(blob_name)\n",
        "        blob.upload_from_filename(local_file)\n",
        "        print(\"Copied {} to {}.\".format(local_file, gcs_file_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf7f82732e61"
      },
      "source": [
        "## Upload and Deploy models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc26e68d7b0"
      },
      "source": [
        "This section uploads the model to Model Registry and deploys it to a Vertex AI Endpoint resource.\n",
        "\n",
        "The model deployment step will take ~30 minutes to complete."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd7b56421392"
      },
      "source": [
        "### Text-to-image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d331b1ea337"
      },
      "source": [
        "Deploy the stable diffusion xl model for the text-to-image task. In this example, we deploy the model together with a LoRA.\n",
        "\n",
        "The `lora-id` can either be a resource name in [Huggingface.co](https://huggingface.co), or a GCS path where the LoRA adaptper was downloaded before hand.\n",
        "* [Artificialguybr/ToyRedmond-ToyLoraForSDXL10](https://huggingface.co/artificialguybr/ToyRedmond-ToyLoraForSDXL10)\n",
        "* Download the [ToyRedmond](https://civitai.com/models/125315/toyredmond-toy-lora-for-sd-xl-10) from Civitai.com and save it to a GCS bucket.\n",
        "\n",
        "Once deployed, you can send a batch of text prompts to the endpoint to generated images.\n",
        "\n",
        "Please note that this step is going to take at least 15-30 mins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf55e38815dc"
      },
      "outputs": [],
      "source": [
        "if(HUGGINGFACE_MODE):\n",
        "  #Use a LoRA adapter from huggingface.co\n",
        "  model, endpoint = deploy_model(\n",
        "      model_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "      lora_id=\"artificialguybr/ToyRedmond-ToyLoraForSDXL10\",\n",
        "  )\n",
        "else:\n",
        "  #OR download a LoRA adapter first and save it to a GCS bucket\n",
        "  ! rm -r /tmp/lora-adapter\n",
        "  ! mkdir /tmp/lora-adapter\n",
        "\n",
        "  url = \"https://civitai.com/api/download/models/136880\"  # @param {type:\"string\"}\n",
        "  destination_folder = \"/tmp/lora-adapter\"\n",
        "  file_name = \"ToyRedmond-FnkRedmAF.safetensors\"  # @param {type:\"string\"}\n",
        "\n",
        "  target = f\"{destination_folder}/{file_name}\"\n",
        "\n",
        "  !gdown --fuzzy -O $target \"$url\"\n",
        "  upload_local_dir_to_gcs(\"/tmp/lora-adapter\", f\"gs://{GCS_BUCKET}/lora-adapter\")\n",
        "\n",
        "  model, endpoint = deploy_model(\n",
        "      model_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "      lora_id=f\"gs://{GCS_BUCKET}/lora-adapter\",\n",
        "  )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af21a3cff1e0"
      },
      "source": [
        "### Print Model ID and Endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (f\"Model ID: {model.resource_name}\")\n",
        "print (f\"Model ID: {model.name} -> Take a note to copy this in other notebooks\")\n",
        "print (f\"Endpoint: {endpoint.resource_name}\")\n",
        "print (f\"Endpoint: {endpoint.name} -> Take a note to copy this in other notebooks\")"
      ],
      "metadata": {
        "id": "jpf1DTi-5ybO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_garden_pytorch_stable_diffusion_xl_lora.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
